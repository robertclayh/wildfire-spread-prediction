{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8f8d0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12584\\3915901636.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Silence pipeline init logs when possible and load shared DataPipeline helpers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MNDWS_PIPELINE_SILENT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mNDWS_DataPipeline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\AppData\\Local\\ESRI\\conda\\envs\\arcpro-clone\\Lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harrisrc\\OneDrive - Chesterfield County VA\\Documents\\MSDS\\DS6050\\wildfire-spread-prediction\\mNDWS_DataPipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Prev/next-day fire visualization pairs for presentation\n",
    "import os\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Silence pipeline init logs when possible and load shared DataPipeline helpers\n",
    "os.environ.setdefault(\"MNDWS_PIPELINE_SILENT\", \"1\")\n",
    "pipeline = importlib.import_module(\"mNDWS_DataPipeline\")\n",
    "\n",
    "val_ds = pipeline.val_ds\n",
    "channel_names = list(val_ds.channels)\n",
    "prev_idx = channel_names.index(\"prev_fire\")\n",
    "rng = np.random.default_rng(2024)\n",
    "n_samples = min(3, len(val_ds))\n",
    "sample_indices = rng.choice(len(val_ds), size=n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 2, figsize=(10, 3.8 * n_samples))\n",
    "if n_samples == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for row, idx in enumerate(sample_indices):\n",
    "    sample = val_ds[idx]\n",
    "    prev_fire = sample[\"X_raw\"][prev_idx].numpy()\n",
    "    next_fire = sample[\"y\"][0].numpy()\n",
    "    tile_name = Path(val_ds.files[idx]).stem\n",
    "    ax_prev, ax_next = axes[row]\n",
    "    im0 = ax_prev.imshow(prev_fire, cmap=\"magma\", vmin=0, vmax=1)\n",
    "    ax_prev.set_title(f\"Prev day fire | {tile_name}\")\n",
    "    ax_prev.axis(\"off\")\n",
    "    im1 = ax_next.imshow(next_fire, cmap=\"inferno\", vmin=0, vmax=1)\n",
    "    ax_next.set_title(\"Next day fire spread\")\n",
    "    ax_next.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Prev-Day vs Next-Day Fire Masks (validation samples)\", fontsize=14, y=0.94)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline metrics when using previous-day fire mask as prediction\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "test_ds = getattr(pipeline, \"test_ds\", None)\n",
    "if test_ds is None:\n",
    "    raise RuntimeError(\"pipeline.test_ds is missing; run mNDWS_DataPipeline first.\")\n",
    "\n",
    "def prev_day_baseline_metrics(dataset):\n",
    "    channel_names = list(dataset.channels)\n",
    "    if \"prev_fire\" not in channel_names:\n",
    "        raise ValueError(\"Dataset does not contain 'prev_fire' channel.\")\n",
    "    prev_idx = channel_names.index(\"prev_fire\")\n",
    "    preds, targets = [], []\n",
    "    for sample in dataset:\n",
    "        prev_fire = sample[\"X_raw\"][prev_idx].numpy().astype(np.float32).reshape(-1)\n",
    "        next_fire = sample[\"y\"][0].numpy().astype(np.float32).reshape(-1)\n",
    "        preds.append(prev_fire)\n",
    "        targets.append(next_fire)\n",
    "    probs = np.concatenate(preds)\n",
    "    truth = np.concatenate(targets)\n",
    "    if truth.sum() == 0:\n",
    "        return dict(ap=0.0, f1=0.0, iou=0.0, best_thr=float(\"nan\"))\n",
    "    ap = float(average_precision_score(truth, probs))\n",
    "    prec, rec, thr = precision_recall_curve(truth, probs)\n",
    "    f1_curve = (2 * prec * rec) / (prec + rec + 1e-8)\n",
    "    best_idx = int(f1_curve.argmax())\n",
    "    best_thr = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "    binary = (probs >= best_thr).astype(np.float32)\n",
    "    tp = float((binary * truth).sum())\n",
    "    fp = float((binary * (1 - truth)).sum())\n",
    "    fn = float(((1 - binary) * truth).sum())\n",
    "    iou = tp / (tp + fp + fn + 1e-8)\n",
    "    return dict(ap=ap, f1=float(f1_curve[best_idx]), iou=float(iou), best_thr=best_thr)\n",
    "\n",
    "val_metrics = prev_day_baseline_metrics(val_ds)\n",
    "test_metrics = prev_day_baseline_metrics(test_ds)\n",
    "\n",
    "print(\"Prev-mask baseline metrics:\")\n",
    "print(f\"  Validation → AP {val_metrics['ap']:.4f} | F1 {val_metrics['f1']:.4f} | IoU {val_metrics['iou']:.4f} | best_thr≈{val_metrics['best_thr']:.3f}\")\n",
    "print(f\"  Test        → AP {test_metrics['ap']:.4f} | F1 {test_metrics['f1']:.4f} | IoU {test_metrics['iou']:.4f} | best_thr≈{test_metrics['best_thr']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpro-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
